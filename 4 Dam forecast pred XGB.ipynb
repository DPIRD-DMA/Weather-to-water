{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cbb1513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook applies the GXBoost model to a years worth a cliamte data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bc51d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import glob\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "from datetime import datetime\n",
    "import dateutil.relativedelta\n",
    "import json\n",
    "from pathlib import Path\n",
    "from threading import Thread\n",
    "import warnings\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "from multiprocess import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdd91f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'dam_forecast_11-10-22.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af69a5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('found model?', True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in vars\n",
    "%store -r dam_forcast_working_dir\n",
    "%store -r min_year\n",
    "%store -r max_year\n",
    "%store -r climate_types\n",
    "%store -r point_data_input_path\n",
    "%store -r dam_forcast_working_dir\n",
    "%store -r time_step_folder\n",
    "# set up some folders\n",
    "output_folder = os.path.join(dam_forcast_working_dir,'monthly output')\n",
    "Path(output_folder).mkdir(exist_ok=True)\n",
    "# location of model file\n",
    "model_folder = os.path.join(os.getcwd(),'data')\n",
    "model_path = os.path.join(model_folder,model_name)\n",
    "'found model?',os.path.isfile(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e645d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in data from meta file\n",
    "with open(model_path.replace('.pkl','.json'), 'r') as fp:\n",
    "    meta_dict = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54174168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load up model\n",
    "xgb_reg_models = pickle.load(open(model_path, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac65a52d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a refence to each time step\n",
    "time_steps = glob.glob(time_step_folder+'/*.pkl')\n",
    "len(time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e6c235b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# open vector data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m dam_points \u001b[38;5;241m=\u001b[39m \u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoint_data_input_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m dam_points\u001b[38;5;241m.\u001b[39mhead()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# reproject to WGS 84 if not already\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/df/lib/python3.8/site-packages/geopandas/io/file.py:259\u001b[0m, in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, rows, engine, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m     path_or_bytes \u001b[38;5;241m=\u001b[39m filename\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiona\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read_file_fiona\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyogrio\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _read_file_pyogrio(\n\u001b[1;32m    264\u001b[0m         path_or_bytes, bbox\u001b[38;5;241m=\u001b[39mbbox, mask\u001b[38;5;241m=\u001b[39mmask, rows\u001b[38;5;241m=\u001b[39mrows, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    265\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/df/lib/python3.8/site-packages/geopandas/io/file.py:360\u001b[0m, in \u001b[0;36m_read_file_fiona\u001b[0;34m(path_or_bytes, from_bytes, bbox, mask, rows, where, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[1;32m    357\u001b[0m         [record[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproperties\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m f_filt], columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[1;32m    358\u001b[0m     )\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 360\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mGeoDataFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_features\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf_filt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgeometry\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m datetime_fields:\n\u001b[1;32m    364\u001b[0m     as_dt \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[k], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/df/lib/python3.8/site-packages/geopandas/geodataframe.py:630\u001b[0m, in \u001b[0;36mGeoDataFrame.from_features\u001b[0;34m(cls, features, crs, columns)\u001b[0m\n\u001b[1;32m    627\u001b[0m     features_lst \u001b[38;5;241m=\u001b[39m features\n\u001b[1;32m    629\u001b[0m rows \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 630\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m features_lst:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# load geometry\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(feature, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__geo_interface__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    633\u001b[0m         feature \u001b[38;5;241m=\u001b[39m feature\u001b[38;5;241m.\u001b[39m__geo_interface__\n",
      "File \u001b[0;32mfiona/ogrext.pyx:1507\u001b[0m, in \u001b[0;36mfiona.ogrext.Iterator.__next__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfiona/ogrext.pyx:1494\u001b[0m, in \u001b[0;36mfiona.ogrext.Iterator._next\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/df/lib/python3.8/logging/__init__.py:1433\u001b[0m, in \u001b[0;36mLogger.debug\u001b[0;34m(self, msg, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdebug\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1425\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;124;03m    Log 'msg % args' with severity 'DEBUG'.\u001b[39;00m\n\u001b[1;32m   1427\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1431\u001b[0m \u001b[38;5;124;03m    logger.debug(\"Houston, we have a %s\", \"thorny problem\", exc_info=1)\u001b[39;00m\n\u001b[1;32m   1432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1433\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misEnabledFor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEBUG\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1434\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log(DEBUG, msg, args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# open vector data\n",
    "dam_points = gpd.read_file(point_data_input_path)\n",
    "dam_points.head()\n",
    "# reproject to WGS 84 if not already\n",
    "if dam_points.crs.to_epsg() != 4326:\n",
    "    print('Reprojecting')\n",
    "    dam_points = dam_points.to_crs(\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0610ada0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this func takes in input date and return 13 months worth climate data for each point\n",
    "def build_inf_df(start_date):\n",
    "#     convert string date to datetime\n",
    "    start_date_dt = datetime.strptime(start_date, '%Y%m')\n",
    "    point_sample_df_list = []\n",
    "#     loop over each calimte and relative month\n",
    "    for climate_type in climate_types:\n",
    "            for month_shift in range(0,13):\n",
    "#                 get actual date from relative month\n",
    "                shifted_date_dt = start_date_dt - dateutil.relativedelta.relativedelta(months=month_shift)\n",
    "#                 build export path\n",
    "                month_str = str(shifted_date_dt.month).zfill(2)\n",
    "                file_name = f'{shifted_date_dt.year}{month_str}_{climate_type}.pkl'\n",
    "                relative_date_name = f'{climate_type}_{month_shift}_months before'\n",
    "                time_step_file_path = os.path.join(time_step_folder,file_name)\n",
    "#                 open file and name col name relative\n",
    "                try:\n",
    "                    point_sample_df = pd.read_pickle(time_step_file_path)\n",
    "\n",
    "                    point_sample_df.rename(columns={point_sample_df.columns[0]: relative_date_name}, inplace=True)\n",
    "\n",
    "                    point_sample_df_list.append(point_sample_df)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "#     combine all data\n",
    "    all_time_steps = pd.concat(point_sample_df_list,axis=1)\n",
    "    \n",
    "    all_time_steps_with_point_data = pd.concat([dam_points['dam_area'],all_time_steps],axis=1)\n",
    "#     make sure all data is in correct order\n",
    "    all_time_steps_with_point_data = all_time_steps_with_point_data.reindex(meta_dict['col_names'], axis=1)\n",
    "\n",
    "    return all_time_steps_with_point_data        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "243ad8fe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dam_area</th>\n",
       "      <th>rain_0_months before</th>\n",
       "      <th>rain_10_months before</th>\n",
       "      <th>rain_11_months before</th>\n",
       "      <th>rain_12_months before</th>\n",
       "      <th>rain_1_months before</th>\n",
       "      <th>rain_2_months before</th>\n",
       "      <th>rain_3_months before</th>\n",
       "      <th>rain_4_months before</th>\n",
       "      <th>rain_5_months before</th>\n",
       "      <th>...</th>\n",
       "      <th>tavg_12_months before</th>\n",
       "      <th>tavg_1_months before</th>\n",
       "      <th>tavg_2_months before</th>\n",
       "      <th>tavg_3_months before</th>\n",
       "      <th>tavg_4_months before</th>\n",
       "      <th>tavg_5_months before</th>\n",
       "      <th>tavg_6_months before</th>\n",
       "      <th>tavg_7_months before</th>\n",
       "      <th>tavg_8_months before</th>\n",
       "      <th>tavg_9_months before</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1782.758036</td>\n",
       "      <td>91.389145</td>\n",
       "      <td>102.111046</td>\n",
       "      <td>15.942660</td>\n",
       "      <td>34.318153</td>\n",
       "      <td>41.518482</td>\n",
       "      <td>29.074463</td>\n",
       "      <td>66.378281</td>\n",
       "      <td>41.120415</td>\n",
       "      <td>80.803795</td>\n",
       "      <td>...</td>\n",
       "      <td>24.253502</td>\n",
       "      <td>20.431652</td>\n",
       "      <td>20.566591</td>\n",
       "      <td>15.726265</td>\n",
       "      <td>12.332435</td>\n",
       "      <td>8.657789</td>\n",
       "      <td>8.072989</td>\n",
       "      <td>8.438752</td>\n",
       "      <td>10.184371</td>\n",
       "      <td>14.459160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1917.350912</td>\n",
       "      <td>91.599861</td>\n",
       "      <td>60.374527</td>\n",
       "      <td>86.209282</td>\n",
       "      <td>103.682495</td>\n",
       "      <td>92.023117</td>\n",
       "      <td>43.234932</td>\n",
       "      <td>137.324905</td>\n",
       "      <td>85.224243</td>\n",
       "      <td>133.838364</td>\n",
       "      <td>...</td>\n",
       "      <td>18.292000</td>\n",
       "      <td>15.620107</td>\n",
       "      <td>16.618374</td>\n",
       "      <td>13.130466</td>\n",
       "      <td>11.563720</td>\n",
       "      <td>9.255119</td>\n",
       "      <td>8.712623</td>\n",
       "      <td>9.055582</td>\n",
       "      <td>10.510744</td>\n",
       "      <td>13.301476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2300.790143</td>\n",
       "      <td>94.956673</td>\n",
       "      <td>101.596077</td>\n",
       "      <td>55.016685</td>\n",
       "      <td>65.366745</td>\n",
       "      <td>87.820847</td>\n",
       "      <td>52.842342</td>\n",
       "      <td>129.010971</td>\n",
       "      <td>107.157036</td>\n",
       "      <td>113.654251</td>\n",
       "      <td>...</td>\n",
       "      <td>15.991950</td>\n",
       "      <td>13.331125</td>\n",
       "      <td>13.894073</td>\n",
       "      <td>10.666141</td>\n",
       "      <td>9.386144</td>\n",
       "      <td>7.773449</td>\n",
       "      <td>7.490423</td>\n",
       "      <td>8.403605</td>\n",
       "      <td>9.665147</td>\n",
       "      <td>11.672211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>403.480805</td>\n",
       "      <td>25.214075</td>\n",
       "      <td>10.155920</td>\n",
       "      <td>46.595879</td>\n",
       "      <td>18.252161</td>\n",
       "      <td>24.598694</td>\n",
       "      <td>21.089201</td>\n",
       "      <td>67.211670</td>\n",
       "      <td>64.161491</td>\n",
       "      <td>58.338249</td>\n",
       "      <td>...</td>\n",
       "      <td>20.686340</td>\n",
       "      <td>17.684000</td>\n",
       "      <td>19.030613</td>\n",
       "      <td>13.551085</td>\n",
       "      <td>12.200335</td>\n",
       "      <td>9.097849</td>\n",
       "      <td>8.387416</td>\n",
       "      <td>8.973354</td>\n",
       "      <td>10.934418</td>\n",
       "      <td>14.367694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1774.881116</td>\n",
       "      <td>48.494244</td>\n",
       "      <td>111.083740</td>\n",
       "      <td>99.955391</td>\n",
       "      <td>46.732124</td>\n",
       "      <td>128.312881</td>\n",
       "      <td>73.006340</td>\n",
       "      <td>86.361069</td>\n",
       "      <td>71.220161</td>\n",
       "      <td>54.039902</td>\n",
       "      <td>...</td>\n",
       "      <td>24.156582</td>\n",
       "      <td>18.429838</td>\n",
       "      <td>17.916143</td>\n",
       "      <td>14.671591</td>\n",
       "      <td>11.413791</td>\n",
       "      <td>7.220846</td>\n",
       "      <td>7.222924</td>\n",
       "      <td>7.851370</td>\n",
       "      <td>9.137348</td>\n",
       "      <td>13.591210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dam_area  rain_0_months before  rain_10_months before  \\\n",
       "0  1782.758036             91.389145             102.111046   \n",
       "1  1917.350912             91.599861              60.374527   \n",
       "2  2300.790143             94.956673             101.596077   \n",
       "3   403.480805             25.214075              10.155920   \n",
       "4  1774.881116             48.494244             111.083740   \n",
       "\n",
       "   rain_11_months before  rain_12_months before  rain_1_months before  \\\n",
       "0              15.942660              34.318153             41.518482   \n",
       "1              86.209282             103.682495             92.023117   \n",
       "2              55.016685              65.366745             87.820847   \n",
       "3              46.595879              18.252161             24.598694   \n",
       "4              99.955391              46.732124            128.312881   \n",
       "\n",
       "   rain_2_months before  rain_3_months before  rain_4_months before  \\\n",
       "0             29.074463             66.378281             41.120415   \n",
       "1             43.234932            137.324905             85.224243   \n",
       "2             52.842342            129.010971            107.157036   \n",
       "3             21.089201             67.211670             64.161491   \n",
       "4             73.006340             86.361069             71.220161   \n",
       "\n",
       "   rain_5_months before  ...  tavg_12_months before  tavg_1_months before  \\\n",
       "0             80.803795  ...              24.253502             20.431652   \n",
       "1            133.838364  ...              18.292000             15.620107   \n",
       "2            113.654251  ...              15.991950             13.331125   \n",
       "3             58.338249  ...              20.686340             17.684000   \n",
       "4             54.039902  ...              24.156582             18.429838   \n",
       "\n",
       "   tavg_2_months before  tavg_3_months before  tavg_4_months before  \\\n",
       "0             20.566591             15.726265             12.332435   \n",
       "1             16.618374             13.130466             11.563720   \n",
       "2             13.894073             10.666141              9.386144   \n",
       "3             19.030613             13.551085             12.200335   \n",
       "4             17.916143             14.671591             11.413791   \n",
       "\n",
       "   tavg_5_months before  tavg_6_months before  tavg_7_months before  \\\n",
       "0              8.657789              8.072989              8.438752   \n",
       "1              9.255119              8.712623              9.055582   \n",
       "2              7.773449              7.490423              8.403605   \n",
       "3              9.097849              8.387416              8.973354   \n",
       "4              7.220846              7.222924              7.851370   \n",
       "\n",
       "   tavg_8_months before  tavg_9_months before  \n",
       "0             10.184371             14.459160  \n",
       "1             10.510744             13.301476  \n",
       "2              9.665147             11.672211  \n",
       "3             10.934418             14.367694  \n",
       "4              9.137348             13.591210  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run a test extraction\n",
    "test_df = build_inf_df('202101')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b8a8714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dam_area',\n",
       " 'rain_0_months before',\n",
       " 'rain_10_months before',\n",
       " 'rain_11_months before',\n",
       " 'rain_12_months before',\n",
       " 'rain_1_months before',\n",
       " 'rain_2_months before',\n",
       " 'rain_3_months before',\n",
       " 'rain_4_months before',\n",
       " 'rain_5_months before',\n",
       " 'rain_6_months before',\n",
       " 'rain_7_months before',\n",
       " 'rain_8_months before',\n",
       " 'rain_9_months before',\n",
       " 'tavg_0_months before',\n",
       " 'tavg_10_months before',\n",
       " 'tavg_11_months before',\n",
       " 'tavg_12_months before',\n",
       " 'tavg_1_months before',\n",
       " 'tavg_2_months before',\n",
       " 'tavg_3_months before',\n",
       " 'tavg_4_months before',\n",
       " 'tavg_5_months before',\n",
       " 'tavg_6_months before',\n",
       " 'tavg_7_months before',\n",
       " 'tavg_8_months before',\n",
       " 'tavg_9_months before']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the above df should have these cols\n",
    "meta_dict['col_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8ddb70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a list of the start times\n",
    "time_steps = []\n",
    "for year in range(min_year,max_year+1):\n",
    "#     loop over each month\n",
    "    for month in range(1,13):\n",
    "        month = str(month).zfill(2)\n",
    "        time_steps.append(f'{year}{month}')\n",
    "len(time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e6fc5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# func to run the model when given a start time\n",
    "def run_model(time_step):\n",
    "#     build inf df\n",
    "    ts_df = build_inf_df(time_step)\n",
    "#     loop over each model, and combine preds\n",
    "    preds_df = pd.DataFrame()\n",
    "    for model in xgb_reg_models:\n",
    "        preds = model['model'].predict(ts_df)\n",
    "        preds = preds*(preds>0)\n",
    "        preds_df[model['model_number']] = preds\n",
    "        \n",
    "    preds_mean = preds_df.mean(axis=1).to_list()\n",
    "    \n",
    "#     make df with just files names to index to\n",
    "    limited_df = pd.DataFrame(dam_points['file_name'].copy())\n",
    "#     place the preds into df with time a col heading\n",
    "    limited_df[time_step] = preds_mean\n",
    "#     build export path\n",
    "    file_name = f'{time_step}.pkl'\n",
    "    pkl_out_path = os.path.join(output_folder,file_name)\n",
    "#     export to disk\n",
    "    limited_df.to_pickle(pkl_out_path)\n",
    "    \n",
    "    return pkl_out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc6d5dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd3e853b539c4349b93296c87f00279f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'XGBModel' object has no attribute 'callbacks'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/Nick/opt/anaconda3/envs/df/lib/python3.8/site-packages/multiprocess/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/var/folders/kq/rs7d6smx5kv8n5mp22x8kgjr0000gq/T/ipykernel_60592/2073278637.py\", line 8, in run_model\n    preds = model['model'].predict(ts_df)\n  File \"/Users/Nick/opt/anaconda3/envs/df/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1138, in predict\n    if self._can_use_inplace_predict():\n  File \"/Users/Nick/opt/anaconda3/envs/df/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1073, in _can_use_inplace_predict\n    predictor = self.get_params().get(\"predictor\", None)\n  File \"/Users/Nick/opt/anaconda3/envs/df/lib/python3.8/site-packages/xgboost/sklearn.py\", line 695, in get_params\n    params.update(cp.__class__.get_params(cp, deep))\n  File \"/Users/Nick/opt/anaconda3/envs/df/lib/python3.8/site-packages/xgboost/sklearn.py\", line 692, in get_params\n    params = super().get_params(deep)\n  File \"/Users/Nick/opt/anaconda3/envs/df/lib/python3.8/site-packages/sklearn/base.py\", line 211, in get_params\n    value = getattr(self, key)\nAttributeError: 'XGBModel' object has no attribute 'callbacks'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Pool(\u001b[38;5;241m10\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[0;32m----> 2\u001b[0m     monthly_ouputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtime_steps\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtime_steps\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/df/lib/python3.8/site-packages/tqdm/notebook.py:259\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(tqdm_notebook, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 259\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/df/lib/python3.8/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/df/lib/python3.8/site-packages/multiprocess/pool.py:868\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m    867\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[0;32m--> 868\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'XGBModel' object has no attribute 'callbacks'"
     ]
    }
   ],
   "source": [
    "with Pool(10) as p:\n",
    "    monthly_ouputs = list(tqdm(p.imap(run_model,time_steps),total=len(time_steps)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a962de",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_ouputs = glob.glob(output_folder+'/*.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7358756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of all prediction files\n",
    "len(monthly_ouputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f60eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dam_points.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064470b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make empty df to load preds into, we need to keep this separate from the base data we we can sort it by date\n",
    "# this is a slow way to do this but it keep the RAM useage low\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "preds_df = pd.DataFrame()\n",
    "# loop over each pred csv\n",
    "for pkl in tqdm(monthly_ouputs):\n",
    "#     get the file name\n",
    "    file_name = os.path.basename(pkl)\n",
    "#     get the date from the name\n",
    "    date = file_name.replace('.pkl','')\n",
    "#     open file\n",
    "    current_df = pd.read_pickle(pkl)\n",
    "#     extract the preds col\n",
    "    preds = current_df[date].to_list()\n",
    "#     name date a proper python date\n",
    "    date_fixed = datetime.strptime(date, '%Y%m')\n",
    "#     load preds into main df\n",
    "    preds_df[date_fixed] = preds\n",
    "# sort the cols by date\n",
    "preds_df = preds_df[sorted(preds_df.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6861c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set any negative values to 0\n",
    "preds_df[preds_df < 0] = 0\n",
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfd65bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the input dam points data with the preds\n",
    "preds_with_meta = pd.concat([dam_points, preds_df], axis=1)\n",
    "preds_with_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6233a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert col headings to strings to improve file compatability\n",
    "str_names_dict = {}\n",
    "for name in preds_with_meta.columns.to_list():\n",
    "    str_names_dict[name] = str(name)\n",
    "    \n",
    "preds_with_meta = preds_with_meta.rename(index=str, columns=str_names_dict)\n",
    "preds_with_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ab915a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make csv export path\n",
    "final_export = os.path.join(dam_forcast_working_dir,'Dam forecast preds v6.csv')\n",
    "final_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdd77ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make gpkg export path\n",
    "gpkg_file_name = final_export.replace('.csv','.gpkg')\n",
    "gpkg_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a357933",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# export files\n",
    "preds_with_meta.to_csv(final_export)\n",
    "final_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88663294",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_with_meta.to_file(gpkg_file_name,driver='GPKG')\n",
    "gpkg_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d40802a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
